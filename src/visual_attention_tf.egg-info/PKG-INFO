Metadata-Version: 2.1
Name: visual-attention-tf
Version: 1.0.1
Summary: CNN Attention layer to be used with tf or tf.keras 
Home-page: https://github.com/vinayak19th/Visual_attention_tf
Author: Vinayak Sharma
Author-email: vinayak19th@gmail.com
License: MIT
Project-URL: Bug Tracker, https://github.com/vinayak19th/Visual_attention_tf/issues
Description: # Visual_attention_tf
        A set of image attention layers implemented as custom keras layers that can be imported dirctly into keras
        
        
        ## Currently Implemented layers:
        * Pixel Attention : [Efficient Image Super-Resolution Using Pixel Attention(Hengyuan Zhao et al)](https://arxiv.org/abs/2010.01073)
        * Channel Attention : [CBAM: Convolutional Block Attention Module(Sanghyun Woo et al)](https://arxiv.org/abs/1807.06521)
        
        # Usage:
        ```python
        from tensorflow.keras.models import Model
        from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, SeparableConv2D, Concatenate, Multiply, Add
        from 
        ```
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
